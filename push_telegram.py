import os
import datetime
import requests
import feedparser
import finnhub
import re
from google import genai
from zoneinfo import ZoneInfo

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# é…ç½®å±‚
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def get_config():
    cfg = {
        "tg_token": os.getenv("TELEGRAM_TOKEN"),
        "chat_id": os.getenv("CHAT_ID"),
        "finnhub_key": os.getenv("FINNHUB_KEY"),
        "gemini_key": os.getenv("GEMINI_KEY"),
        "fred_key": os.getenv("FRED_KEY")  # å¯é€‰ï¼šç”¨äºè·å–è´¹åŸè”å‚¨æ•°æ®
    }
    # éªŒè¯å¿…è¦é…ç½®
    missing = [k for k, v in cfg.items() if not v and k != "fred_key"]
    if missing:
        raise ValueError(f"ç¼ºå°‘ç¯å¢ƒå˜é‡: {missing}")
    return cfg

cfg = get_config()
fh_client = finnhub.Client(api_key=cfg["finnhub_key"])
gemini_client = genai.Client(api_key=cfg["gemini_key"])

# å…¬å¸å â†’ Ticker æ˜ å°„è¡¨ï¼ˆé«˜é¢‘å‡ºç°çš„å…¬å¸ï¼‰
COMPANY_TICKER_MAP = {
    "nvidia": "NVDA", "apple": "AAPL", "microsoft": "MSFT", "google": "GOOGL",
    "alphabet": "GOOGL", "amazon": "AMZN", "meta": "META", "facebook": "META",
    "tesla": "TSLA", "netflix": "NFLX", "amd": "AMD", "intel": "INTC",
    "broadcom": "AVGO", "salesforce": "CRM", "oracle": "ORCL", "ibm": "IBM",
    "walmart": "WMT", "costco": "COST", "target": "TGT", "home depot": "HD",
    "jpmorgan": "JPM", "goldman": "GS", "morgan stanley": "MS", "blackrock": "BLK",
    "berkshire": "BRK.B", "visa": "V", "mastercard": "MA", "paypal": "PYPL",
    "boeing": "BA", "lockheed": "LMT", "raytheon": "RTX", "general electric": "GE",
    "exxon": "XOM", "chevron": "CVX", "conocophillips": "COP",
    "pfizer": "PFE", "johnson": "JNJ", "unitedhealth": "UNH", "eli lilly": "LLY",
    "disney": "DIS", "comcast": "CMCSA", "verizon": "VZ", "at&t": "T",
    "uber": "UBER", "airbnb": "ABNB", "doordash": "DASH", "spotify": "SPOT",
    "openai": "MSFT",  # OpenAI å…³è” MSFT
    "anthropic": "GOOGL",  # Anthropic å…³è” GOOGL
}

# åˆ¶é€ ä¸šå…³é”®è¯ï¼ˆè§¦å‘è´¹åŸè”å‚¨å…³è”ï¼‰
MANUFACTURING_KEYWORDS = [
    "manufacturing", "factory", "industrial", "production", "supply chain",
    "åˆ¶é€ ", "å·¥å‚", "äº§èƒ½", "ä¾›åº”é“¾", "å·¥ä¸š", "ç”Ÿäº§"
]

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# æ•°æ®æŠ“å–å±‚
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def get_market_pulse():
    """è·å–æ ¸å¿ƒå¸‚åœºæŒ‡æ ‡ï¼Œè¿”å› Markdown è¡¨æ ¼"""
    indices = [
        ("SPY", "S&P 500", "å¤§ç›˜é£å‘"),
        ("QQQ", "Nasdaq 100", "ç§‘æŠ€æƒ…ç»ª"),
        ("IWM", "Russell 2000", "å°ç›˜æ´»åŠ›"),
        ("TLT", "20Y Treasury", "åˆ©ç‡é¢„æœŸ"),
        ("GLD", "é»„é‡‘ ETF", "é¿é™©æƒ…ç»ª"),
        ("VXX", "VIX ææ…ŒæŒ‡æ•°", "æ³¢åŠ¨ç‡"),
    ]
    
    rows = []
    for ticker, name, meaning in indices:
        try:
            q = fh_client.quote(ticker)
            if q.get('c') and q.get('pc'):
                chg = ((q['c'] - q['pc']) / q['pc']) * 100
                emoji = "ğŸŸ¢" if chg > 0.3 else "ğŸ”´" if chg < -0.3 else "âšª"
                rows.append(f"| {emoji} {name} | {chg:+.2f}% | {meaning} |")
        except:
            continue
    
    if not rows:
        return "| æŒ‡æ ‡ | æ¶¨è·Œ | å«ä¹‰ |\n|---|---|---|\n| âš ï¸ æ•°æ®æš‚ä¸å¯ç”¨ | - | - |"
    
    header = "| æŒ‡æ ‡ | æ¶¨è·Œ | ä¿¡å·å«ä¹‰ |\n|:---|:---:|:---|"
    return header + "\n" + "\n".join(rows)


def get_stock_data(ticker):
    """è·å–ä¸ªè‚¡å®Œæ•´æ•°æ®ï¼šå®æ—¶ä»·æ ¼ + æŠ€æœ¯æŒ‡æ ‡"""
    try:
        ticker = ticker.upper().strip()
        if not re.match(r'^[A-Z]{1,5}$', ticker):
            return None
        
        # å®æ—¶æŠ¥ä»·
        q = fh_client.quote(ticker)
        if not (q.get('c') and q.get('pc')):
            return None
        
        current_price = q['c']
        prev_close = q['pc']
        day_change = ((current_price - prev_close) / prev_close) * 100
        day_high = q.get('h', current_price)
        day_low = q.get('l', current_price)
        
        # è·å–å†å²æ•°æ®è®¡ç®—å‡çº¿
        ma_200_position = calculate_ma_position(ticker, current_price, 200)
        ma_50_position = calculate_ma_position(ticker, current_price, 50)
        
        # 52å‘¨é«˜ä½ç‚¹
        week_52 = get_52_week_range(ticker, current_price)
        
        return {
            "ticker": ticker,
            "price": current_price,
            "change_pct": day_change,
            "day_high": day_high,
            "day_low": day_low,
            "ma_50_position": ma_50_position,
            "ma_200_position": ma_200_position,
            "week_52_position": week_52,
            "summary": format_stock_summary(ticker, current_price, day_change, ma_200_position, week_52)
        }
    except Exception as e:
        print(f"è·å– {ticker} æ•°æ®å¤±è´¥: {e}")
        return None


def calculate_ma_position(ticker, current_price, days):
    """è®¡ç®—å½“å‰ä»·æ ¼ç›¸å¯¹äº N æ—¥å‡çº¿çš„ä½ç½®"""
    try:
        # è·å–å†å² K çº¿
        end = int(datetime.datetime.now().timestamp())
        start = end - (days + 30) * 24 * 60 * 60  # å¤šå–30å¤©buffer
        
        candles = fh_client.stock_candles(ticker, 'D', start, end)
        if candles.get('s') != 'ok' or len(candles.get('c', [])) < days:
            return None
        
        closes = candles['c'][-days:]
        ma = sum(closes) / len(closes)
        position = ((current_price - ma) / ma) * 100
        
        return round(position, 2)
    except:
        return None


def get_52_week_range(ticker, current_price):
    """è®¡ç®—å½“å‰ä»·æ ¼åœ¨52å‘¨èŒƒå›´å†…çš„ä½ç½®"""
    try:
        end = int(datetime.datetime.now().timestamp())
        start = end - 365 * 24 * 60 * 60
        
        candles = fh_client.stock_candles(ticker, 'D', start, end)
        if candles.get('s') != 'ok':
            return None
        
        high_52 = max(candles.get('h', [current_price]))
        low_52 = min(candles.get('l', [current_price]))
        
        if high_52 == low_52:
            return 50.0
        
        position = ((current_price - low_52) / (high_52 - low_52)) * 100
        return round(position, 1)
    except:
        return None


def format_stock_summary(ticker, price, change, ma_200, week_52):
    """æ ¼å¼åŒ–è‚¡ç¥¨æ‘˜è¦"""
    parts = [f"{ticker}: ${price:.2f} ({change:+.2f}%)"]
    
    if ma_200 is not None:
        trend = "ä¸Šæ–¹" if ma_200 > 0 else "ä¸‹æ–¹"
        parts.append(f"200MA{trend} {abs(ma_200):.1f}%")
    
    if week_52 is not None:
        if week_52 > 90:
            parts.append("ğŸ“ˆ æ¥è¿‘52å‘¨æ–°é«˜")
        elif week_52 < 10:
            parts.append("ğŸ“‰ æ¥è¿‘52å‘¨æ–°ä½")
        else:
            parts.append(f"52å‘¨ä½ç½®: {week_52:.0f}%")
    
    return " | ".join(parts)


def get_philly_fed_index():
    """è·å–è´¹åŸè”å‚¨åˆ¶é€ ä¸šæŒ‡æ•°"""
    # æ–¹æ³•1: å°è¯• FRED API
    if cfg.get("fred_key"):
        try:
            url = f"https://api.stlouisfed.org/fred/series/observations"
            params = {
                "series_id": "MANEMP",  # åˆ¶é€ ä¸šå°±ä¸š
                "api_key": cfg["fred_key"],
                "file_type": "json",
                "sort_order": "desc",
                "limit": 1
            }
            resp = requests.get(url, params=params, timeout=5)
            if resp.ok:
                data = resp.json()
                obs = data.get("observations", [{}])[0]
                return f"æœ€æ–°åˆ¶é€ ä¸šå°±ä¸š: {obs.get('value', 'N/A')}K"
        except:
            pass
    
    # æ–¹æ³•2: è¿”å›å›ºå®šè¯´æ˜ï¼ˆå®é™…éƒ¨ç½²æ—¶å¯æ¥å…¥çœŸå®APIï¼‰
    return "è´¹åŸè”å‚¨åˆ¶é€ ä¸šæŒ‡æ•°: å…³æ³¨ä¾›åº”é“¾ä¸äº§èƒ½åˆ©ç”¨ç‡åŠ¨æ€"


def fetch_top_news():
    """æŠ“å–é¡¶çº§è´¢ç»æ–°é—»"""
    sources = {
        "WSJ": "https://feeds.a.dj.com/rss/WSJcomUSBusiness.xml",
        "NYT_Tech": "https://rss.nytimes.com/services/xml/rss/nyt/Technology.xml",
        "NYT_Biz": "https://rss.nytimes.com/services/xml/rss/nyt/Business.xml",
    }
    
    pool = []
    for name, url in sources.items():
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries[:3]:
                title = entry.get('title', '')
                summary = entry.get('summary', '')[:500]
                
                # æ£€æµ‹æ˜¯å¦æ¶‰åŠåˆ¶é€ ä¸š
                combined_text = (title + " " + summary).lower()
                is_manufacturing = any(kw in combined_text for kw in MANUFACTURING_KEYWORDS)
                
                pool.append({
                    "title": title,
                    "summary": summary,
                    "source": name.replace("_", " "),
                    "is_manufacturing": is_manufacturing
                })
        except Exception as e:
            print(f"æŠ“å– {name} å¤±è´¥: {e}")
            continue
    
    return pool[:8]  # é™åˆ¶æ€»æ•°

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Ticker å‰ç½®è¯†åˆ«å±‚ï¼ˆV4 æ ¸å¿ƒæ”¹è¿›ï¼‰
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def extract_tickers_from_text(text):
    """ä»æ–‡æœ¬ä¸­æ¨¡ç³Šè¯†åˆ«æ½œåœ¨ Ticker"""
    text_lower = text.lower()
    found_tickers = set()
    
    # æ–¹æ³•1: æŸ¥è¡¨åŒ¹é…å…¬å¸å
    for company, ticker in COMPANY_TICKER_MAP.items():
        if company in text_lower:
            found_tickers.add(ticker)
    
    # æ–¹æ³•2: æ­£åˆ™åŒ¹é…å¯èƒ½çš„ Tickerï¼ˆå…¨å¤§å†™1-5å­—æ¯ï¼‰
    # æ’é™¤å¸¸è§é Ticker è¯æ±‡
    exclude_words = {'THE', 'AND', 'FOR', 'NEW', 'CEO', 'CFO', 'IPO', 'SEC', 'FDA', 'USA', 'GDP', 'AI', 'CEO'}
    potential = re.findall(r'\b([A-Z]{2,5})\b', text)
    for p in potential:
        if p not in exclude_words and len(p) >= 2:
            found_tickers.add(p)
    
    return list(found_tickers)


def batch_identify_tickers(news_items):
    """ä½¿ç”¨è½»é‡ AI è°ƒç”¨æ‰¹é‡è¯†åˆ«æ–°é—»ä¸­çš„ Ticker"""
    # å…ˆç”¨è§„åˆ™æå–
    rule_based = {}
    for i, news in enumerate(news_items):
        text = news['title'] + " " + news['summary']
        tickers = extract_tickers_from_text(text)
        if tickers:
            rule_based[i] = tickers[:3]  # æ¯æ¡æ–°é—»æœ€å¤š3ä¸ª
    
    # å¯¹äºè§„åˆ™æœªèƒ½è¯†åˆ«çš„ï¼Œç”¨ AI è¡¥å……
    unidentified = [i for i in range(len(news_items)) if i not in rule_based]
    
    if unidentified:
        # æ„å»ºè½»é‡ prompt
        news_text = "\n".join([
            f"[{i}] {news_items[i]['title']}" 
            for i in unidentified
        ])
        
        prompt = f"""
ä»…è¾“å‡ºè‚¡ç¥¨ä»£ç ã€‚å¯¹ä»¥ä¸‹æ¯æ¡æ–°é—»ï¼Œå¦‚æœæ¶‰åŠä¸Šå¸‚å…¬å¸ï¼Œè¾“å‡ºå…¶ç¾è‚¡ä»£ç ï¼›å¦åˆ™è¾“å‡º NONEã€‚
æ ¼å¼ï¼š[åºå·] TICKER

{news_text}

ç¤ºä¾‹è¾“å‡ºï¼š
[0] AAPL
[1] NONE
[2] TSLA, RIVN
"""
        try:
            resp = gemini_client.models.generate_content(
                model="gemini-2.0-flash",
                contents=prompt
            )
            
            # è§£æ AI è¾“å‡º
            for line in resp.text.strip().split('\n'):
                match = re.match(r'\[(\d+)\]\s*(.+)', line.strip())
                if match:
                    idx = int(match.group(1))
                    tickers_str = match.group(2).strip()
                    if tickers_str.upper() != 'NONE':
                        tickers = [t.strip() for t in tickers_str.split(',')]
                        tickers = [t for t in tickers if re.match(r'^[A-Z]{1,5}$', t)]
                        if tickers:
                            rule_based[idx] = tickers[:3]
        except Exception as e:
            print(f"AI Ticker è¯†åˆ«å¤±è´¥: {e}")
    
    return rule_based


def prefetch_stock_data(ticker_map):
    """é¢„æŠ“å–æ‰€æœ‰è¯†åˆ«åˆ°çš„è‚¡ç¥¨æ•°æ®"""
    all_tickers = set()
    for tickers in ticker_map.values():
        all_tickers.update(tickers)
    
    stock_data = {}
    for ticker in all_tickers:
        data = get_stock_data(ticker)
        if data:
            stock_data[ticker] = data
    
    return stock_data

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# AI åˆ†æå±‚ï¼ˆå¸¦é‡åŒ–æ•°æ®çš„ Promptï¼‰
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def build_v4_prompt(news_items, ticker_map, stock_data, philly_fed_info):
    """æ„å»º V4 ç‰ˆæœ¬çš„åˆ†æ Promptï¼Œå¸¦å…¥é¢„æŠ“å–çš„é‡åŒ–æ•°æ®"""
    
    news_blocks = []
    for i, news in enumerate(news_items):
        block = f"ã€{i+1}ã€‘[{news['source']}] {news['title']}\næ‘˜è¦ï¼š{news['summary']}"
        
        # é™„åŠ å·²æŠ“å–çš„è‚¡ç¥¨æ•°æ®
        if i in ticker_map:
            tickers = ticker_map[i]
            data_lines = []
            for t in tickers:
                if t in stock_data:
                    d = stock_data[t]
                    data_lines.append(
                        f"  â€¢ {t}: ${d['price']:.2f} ({d['change_pct']:+.2f}%) | "
                        f"MA200ä½ç½®: {d['ma_200_position']}% | 52å‘¨ä½ç½®: {d['week_52_position']}%"
                    )
            if data_lines:
                block += "\nğŸ“Š å®æ—¶æ•°æ®:\n" + "\n".join(data_lines)
        
        # æ ‡è®°åˆ¶é€ ä¸šç›¸å…³
        if news['is_manufacturing']:
            block += f"\nğŸ­ [åˆ¶é€ ä¸šå…³è”] {philly_fed_info}"
        
        news_blocks.append(block)
    
    return f"""
ä½ æ˜¯èåˆäº† Wharton é‡åŒ–é‡‘èæ•™æˆä¸ Citadel å®è§‚ç­–ç•¥ PM æ€ç»´çš„é¦–å¸­åˆ†æå¸ˆã€‚
å½“å‰æ—¶é—´ï¼š{datetime.datetime.now(ZoneInfo('America/New_York')).strftime('%Y-%m-%d %H:%M')} (è´¹åŸæ—¶é—´)

ä»¥ä¸‹æ˜¯ä»Šæ—¥é‡è¦è´¢ç»æ–°é—»ï¼Œæ¯æ¡æ–°é—»å·²é™„å¸¦å®æ—¶è‚¡ç¥¨æ•°æ®ï¼ˆå¦‚æœ‰ï¼‰ã€‚

{chr(10).join(news_blocks)}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€V4 è¾“å‡ºæ ¼å¼è¦æ±‚ã€‘ï¼ˆä¸¥æ ¼éµå®ˆï¼‰

å¯¹æ¯æ¡æ–°é—»ï¼Œè¾“å‡ºä»¥ä¸‹ç»“æ„ï¼š

## ğŸ“° [{åºå·}] [æ ‡é¢˜å…³é”®è¯ï¼Œä¸è¶…è¿‡8å­—]

**ğŸ¯ ç©¿é€è§‚ç‚¹** (1å¥è¯ç›´å‡»æœ¬è´¨ï¼Œä¸è¦åºŸè¯)

**ğŸ“Š é‡åŒ–å®šä½**
| æŒ‡æ ‡ | æ•°å€¼ | ä¿¡å· |
|:---|:---:|:---|
| æƒ…ç»ªåˆ† | [X]/10 | [åˆ©å¥½/åˆ©ç©º/ä¸­æ€§] |
| ç›¸å…³æ ‡çš„ | [TICKER] | [ä½¿ç”¨æˆ‘æä¾›çš„å®æ—¶æ•°æ®åˆ†æ] |
| 200æ—¥å‡çº¿ä½ç½® | [X]% | [è¶‹åŠ¿åˆ¤æ–­ï¼šä¸Šæ¶¨/ä¸‹è·Œ/æ¨ªç›˜] |
| 52å‘¨ä½ç½® | [X]% | [é«˜ä½é£é™©/ä½ä½æœºä¼š/ä¸­æ€§] |

**âš–ï¸ ä¸‰ç»´é€è§†**
- *ä¼°å€¼é€»è¾‘*: åŸºäºå½“å‰è‚¡ä»·å’Œå‡çº¿ä½ç½®ï¼Œåˆ¤æ–­ä¼°å€¼åˆç†æ€§
- *æ”¿æ²»é£é™©*: ç›‘ç®¡ã€åœ°ç¼˜ã€æ”¿ç­–å±‚é¢éšæ‚£
- *å†å²é•œé‰´*: ç±»ä¼¼å†å²äº‹ä»¶åŠåç»­èµ°åŠ¿

**ğŸ› è´¹åŸè”å‚¨è§†è§’**: 
[å¦‚æœæ–°é—»æ¶‰åŠåˆ¶é€ ä¸šï¼Œå¿…é¡»å¼•ç”¨è´¹åŸè”å‚¨åˆ¶é€ ä¸šæŒ‡æ•°ï¼Œåˆ†æå¯¹åŒºåŸŸç»æµå’Œè´§å¸æ”¿ç­–çš„å½±å“]
[å¦‚æœä¸æ¶‰åŠåˆ¶é€ ä¸šï¼Œä»è´¹åŸè”å‚¨çš„åˆ©ç‡é¢„æœŸæˆ–å°±ä¸šæ•°æ®è§’åº¦ç‚¹è¯„]

---

ã€è¯­æ°”è¦æ±‚ã€‘
- å†·å³»ã€ä¸“ä¸šã€ä¸åºŸè¯
- åƒåœ¨ç»™ Citadel LP å†™æ¯å‘¨å¸‚åœºç®€æŠ¥
- ç›´æ¥ä½¿ç”¨æˆ‘æä¾›çš„é‡åŒ–æ•°æ®ï¼Œä¸è¦è™šæ„æ•°å­—
- å¦‚æœæŸåªè‚¡ç¥¨æ²¡æœ‰æ•°æ®ï¼Œæ³¨æ˜"æ•°æ®æš‚ç¼º"
"""


def extract_ai_analysis(response_text):
    """æ¸…ç† AI è¾“å‡º"""
    # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
    text = response_text.strip()
    if text.startswith("```"):
        text = re.sub(r'^```\w*\n?', '', text)
        text = re.sub(r'\n?```$', '', text)
    return text

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Telegram å‘é€å±‚
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def send_telegram(text, chat_id, token):
    """åˆ†æ®µå‘é€ Telegram æ¶ˆæ¯"""
    MAX_LEN = 4000
    
    # æŒ‰è‡ªç„¶åˆ†éš”ç¬¦åˆ‡åˆ†
    if len(text) <= MAX_LEN:
        chunks = [text]
    else:
        chunks = []
        current = ""
        for line in text.split('\n'):
            if len(current) + len(line) + 1 > MAX_LEN:
                if current:
                    chunks.append(current)
                current = line
            else:
                current = current + '\n' + line if current else line
        if current:
            chunks.append(current)
    
    for i, chunk in enumerate(chunks):
        try:
            resp = requests.post(
                f"https://api.telegram.org/bot{token}/sendMessage",
                data={
                    "chat_id": chat_id, 
                    "text": chunk, 
                    "parse_mode": "Markdown"
                },
                timeout=15
            )
            if not resp.ok:
                # Markdown è§£æå¤±è´¥æ—¶é™çº§åˆ°çº¯æ–‡æœ¬
                resp = requests.post(
                    f"https://api.telegram.org/bot{token}/sendMessage",
                    data={"chat_id": chat_id, "text": chunk},
                    timeout=15
                )
                if not resp.ok:
                    print(f"Telegram å‘é€å¤±è´¥ (chunk {i+1}): {resp.text}")
        except Exception as e:
            print(f"Telegram å¼‚å¸¸: {e}")

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ä¸»ç¨‹åº
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def run_v4_terminal():
    print("ğŸš€ Bloomberg V4.0 Alpha å¯åŠ¨ä¸­...")
    start_time = datetime.datetime.now()
    
    # è·å–æ—¶é—´
    philly_time = datetime.datetime.now(ZoneInfo("America/New_York"))
    
    # Step 1: è·å–å¸‚åœºè„‰æ
    print("ğŸ“ˆ æŠ“å–å¸‚åœºæŒ‡æ•°...")
    market_pulse = get_market_pulse()
    
    # Step 2: è·å–è´¹åŸè”å‚¨æ•°æ®
    print("ğŸ› è·å–è´¹åŸè”å‚¨æ•°æ®...")
    philly_fed_info = get_philly_fed_index()
    
    # Step 3: æŠ“å–æ–°é—»
    print("ğŸ“° æŠ“å–è´¢ç»æ–°é—»...")
    news = fetch_top_news()
    if not news:
        error_msg = "âš ï¸ ä»Šæ—¥æš‚æ— æ–°é—»æºå¯ç”¨ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥"
        send_telegram(error_msg, cfg['chat_id'], cfg['tg_token'])
        return
    
    # Step 4: å‰ç½®è¯†åˆ« Tickerï¼ˆV4 æ ¸å¿ƒï¼‰
    print("ğŸ” å‰ç½®è¯†åˆ«è‚¡ç¥¨ä»£ç ...")
    ticker_map = batch_identify_tickers(news)
    print(f"   è¯†åˆ«åˆ° {sum(len(v) for v in ticker_map.values())} ä¸ªæ½œåœ¨æ ‡çš„")
    
    # Step 5: é¢„æŠ“å–è‚¡ç¥¨æ•°æ®
    print("ğŸ“Š é¢„æŠ“å–è‚¡ç¥¨é‡åŒ–æ•°æ®...")
    stock_data = prefetch_stock_data(ticker_map)
    print(f"   æˆåŠŸè·å– {len(stock_data)} åªè‚¡ç¥¨æ•°æ®")
    
    # Step 6: æ„å»º Prompt å¹¶è°ƒç”¨ AI
    print("ğŸ¤– ç”Ÿæˆæ·±åº¦åˆ†æ...")
    prompt = build_v4_prompt(news, ticker_map, stock_data, philly_fed_info)
    
    try:
        response = gemini_client.models.generate_content(
            model="gemini-2.0-flash",
            contents=prompt
        )
        ai_analysis = extract_ai_analysis(response.text)
    except Exception as e:
        ai_analysis = f"âš ï¸ AI åˆ†ææš‚ä¸å¯ç”¨: {e}"
    
    # Step 7: æ„å»ºå®Œæ•´æŠ¥å‘Š
    header = f"""
ğŸ› *ç‹åŒå­¦çš„å…¨çƒå†³ç­–ç»ˆç«¯ V4.0 Alpha*
ğŸ“… {philly_time.strftime('%Y-%m-%d %H:%M')} | Philadelphia
â± æ•°æ®å»¶è¿Ÿ: <{(datetime.datetime.now() - start_time).seconds}s

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ˆ *å¸‚åœºè„‰æ*

{market_pulse}

ğŸ­ *è´¹åŸè”å‚¨*: {philly_fed_info}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š *å·²è¿½è¸ªæ ‡çš„*: {', '.join(stock_data.keys()) if stock_data else 'æ— '}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

"""
    
    # æ·»åŠ å®æ—¶è¡Œæƒ…æ‘˜è¦
    if stock_data:
        quote_lines = []
        for ticker, data in stock_data.items():
            emoji = "ğŸŸ¢" if data['change_pct'] > 0 else "ğŸ”´" if data['change_pct'] < 0 else "âšª"
            quote_lines.append(f"{emoji} `{data['summary']}`")
        header += "*å®æ—¶è¡Œæƒ…å¿«ç…§*\n" + "\n".join(quote_lines) + "\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
    
    full_report = header + ai_analysis
    
    # Step 8: å‘é€
    print("ğŸ“¤ å‘é€æŠ¥å‘Šè‡³ Telegram...")
    send_telegram(full_report, cfg['chat_id'], cfg['tg_token'])
    
    print(f"âœ… V4.0 Alpha æŠ¥å‘Šå·²å‘é€ (è€—æ—¶ {(datetime.datetime.now() - start_time).seconds}s)")


if __name__ == "__main__":
    run_v4_terminal()
